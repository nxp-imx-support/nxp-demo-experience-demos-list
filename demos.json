{"demos":[{
    "Machine Learning":[{
        "NNStreamer":[{
             "name": "Object Classification",
             "id": "obj_class_nn",
             "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/MLDemoLauncher.py id",
             "compatible": "imx8mp, imx8mm, imx8qmmek",
             "screenshot": "ml_id.png",
             "icon": "photo-video-solid.svg",
             "description": "An example of how to use NNStreamer to classify objects in a video or camera feed. An internet connection may be required."
         },{
             "name": "Object Detection",
             "id": "obj_detect_nn",
             "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/MLDemoLauncher.py detect",
             "compatible": "imx8mp, imx8mm, imx8qmmek",
             "screenshot": "ml_detect.png",
             "icon": "photo-video-solid.svg",
             "description": "An example of how to use NNStreamer to detect objects in a video or camera feed. An internet connection may be required."
         },{
             "name": "Pose Detection",
             "id": "pose_detect_nn",
             "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/MLDemoLauncher.py pose",
             "compatible": "imx8mp, imx8qmmek",
             "screenshot": "ml_pose.png",
             "icon": "photo-video-solid.svg",
             "description": "An example of how to use NNStreamer to detect a pose in a video or camera feed. An internet connection may be required."
         },{
             "name": "Brand Detection",
             "id": "brand_detect_nn",
             "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/MLDemoLauncher.py brand",
             "compatible": "imx8mp, imx8mm, imx8qmmek",
             "screenshot": "ml_brand.png",
             "icon": "photo-video-solid.svg",
             "description": "An example of how to use NNStreamer to detect a branded item from the United States in a video or camera feed. An internet connection may be required."
         },{
             "name": "ML Gateway",
             "id": "ml_gate_nn",
             "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/MLGateway.py",
             "compatible": "imx8mp, imx8mm",
             "screenshot": "",
             "icon": "photo-video-solid.svg",
             "description": "Application that allows a resource-constraint MCU/MPU systems (clients) to connect and run inferencing on a ML Gateway system (server) that has very high-performance ML capabilities"
         }],
         "pyeIQ":[{
            "name": "Object Classification",
            "id": "obj_class_pyeiq",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/pyeiq_launcher.py small_id",
            "compatible": "imx8ulp",
            "screenshot": "pyeiq_id.png",
            "icon": "photo-video-solid.svg",
            "description": "An example of how to use Python to classify objects in a photo. An internet connection may be required."
        },{
            "name": "Object Detection",
            "id": "obj_detect_pyeiq",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/pyeiq_launcher.py small_detect",
            "compatible": "imx8ulp",
            "screenshot": "pyeiq_detect.png",
            "icon": "photo-video-solid.svg",
            "description": "An example of how to use Python to detect objects in a photo. An internet connection may be required."
        },{
            "name": "Mask Detection",
            "id": "mask_detect_pyeiq",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/pyeiq_launcher.py small_mask",
            "compatible": "imx8ulp",
            "screenshot": "pyeiq_mask.png",
            "icon": "photo-video-solid.svg",
            "description": "An example of how to use Python to detect mask wearing in a photo. An internet connection may be required."
        }],
        "TFLite":[{
            "name": "ML Benchmark",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/MLBenchmark.py",
            "compatible": "imx93",
            "screenshot": "",
            "icon": "cogs-solid.svg",
            "description": "This demo shows the performance of the NPU when compared to the CPU with TensorFlow Lite."
        }],
        "OpenCV":[{
            "name": "Face Recognition",
            "id": "face_recog",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/face_recognition.py",
            "compatible": "imx8mp",
            "screenshot": "face_rec.png",
            "icon": "photo-video-solid.svg",
            "description": "An OpenCV example of how to use machine learning to recognize faces. An internet connection is required."
        },{
            "name": "DMS Demo",
            "id": "dms",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/dms/dms_demo.py",
            "compatible": "imx93",
            "screenshot": "",
            "icon": "photo-video-solid.svg",
            "description": "An example over how to implement a Driver Monitoring System (DMS)  using the NPU. An internet connection is required."
        },{
            "name": "Selfie Segmentation",
            "id": "self_seg",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/machine_learning/segmentation.py",
            "compatible": "imx8mp",
            "screenshot": "selfie.png",
            "icon": "photo-video-solid.svg",
            "description": "An OpenCV example of how to use machine learning to remove a background from a video. An internet connection is required."
        }]
     }]
     },
    {"Multimedia":[{
        "GStreamer":[{
            "name": "Video Test Demo",
            "id": "video_test",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/multimedia/gstreamer/video_test.py",
            "source": "",
            "icon": "photo-video-solid.svg",
            "screenshot": "gst_test_src_screenshot.png",
            "compatible": "imx7ulp, imx8ulp, imx8qxpc0mek, imx8qmmek, imx8mq, imx8mm, imx8mn, imx8mp, imx93",
            "description": "This is a simple demo utility that allows users to play back video captured on a camera or a test source."
        },{
            "name": "Camera using VPU",
            "id": "video_test_vpu",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/multimedia/gstreamer/imx8mp_camera_demo.py --vpu_enc=True",
            "source": "",
            "icon": "photo-video-solid.svg",
            "screenshot": "gst_camera_preview_screenshot.png",
            "compatible": "imx8mp",
            "description": "This is a GStreamer pipeline able to create a camera preview example using VPU to encode and decode the image."
        },{
            "name": "Multi Cameras Preview",
            "id": "video_test_multi",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/multimedia/gstreamer/imx8mp_camera_demo.py --multi_cam=True",
            "source": "",
            "icon": "photo-video-solid.svg",
            "screenshot": "gst_camera_preview_screenshot.png",
            "compatible": "imx8mp",
            "description": "This is a GStreamer pipeline able to create a camera preview example using a Basler camera and an OV5640 camera simultaneously."
        }],
        "ISP":[{
            "name": "ISP Control Demo",
            "id": "isp_control",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/multimedia/gstreamer/imx8mp_isp_demo.py",
            "source": "",
            "icon": "photo-video-solid.svg",
            "screenshot": "isp_demo.png",
            "compatible": "imx8mp",
            "description": "This program opens a GStreamer pipeline and allows the user to change various parameters of the ISP in real time. This demo will only work with a compatible Basler camera."
        },{
            "name": "Video Dump Demo",
            "id": "video_dump",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/multimedia/gstreamer/imx8mp_isp_dump.py",
            "source": "",
            "icon": "photo-video-solid.svg",
            "screenshot": "",
            "compatible": "imx8mp",
            "description": "This program allows users to dump the raw frame data from a camera onto a connected drive. This demo will only work with a compatible Basler camera."
        }],
        "Audio":[{
            "name": "Audio Record",
            "id": "audio_rec",
            "executable": "/home/root/.nxp-demo-experience/scripts/audio/audio_playback/audio_record.sh",
            "source": "",
            "icon": "volume-up-solid.svg",
            "screenshot": "",
            "compatible": "imx7ulp",
            "description": "This test records an audio file from Headphone input with a 10 second duration. Make sure a Headphone is connected to the board."
        },
        {
            "name": "Audio Play",
            "id": "audio_play",
            "executable": "/home/root/.nxp-demo-experience/scripts/audio/audio_playback/audio_play.sh",
            "source": "",
            "icon": "volume-up-solid.svg",
            "screenshot": "",
            "compatible": "imx7ulp",
            "description": "This test plays the audio file recorded on the 'Audio Record' test. Make sure a Headphone is connected to the board. Need to run the 'Audio Record' test first."
        }],
        "Voice":[{
            "name": "i.MX Voice Control",
            "id": "voice",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/audio/voice/voice_demo.py",
            "source": "",
            "icon": "volume-up-solid.svg",
            "screenshot": "",
            "compatible": "imx8mp, imx8mm",
            "description": "See NXP's Voice Technology in action! Use your voice to open and close various applications. This requires 8-MIC Array Board (8MIC-RPI-MX8) installed on the i.MX hardware (Visit NXP.com for help). Please note that this will override '/etc/asound.conf' file. It will be restored if this application is gracefully terminated."
        },
        {
            "name": "i.MX Multimedia Player",
            "id": "btplayer",
            "executable": "/home/root/.nxp-demo-experience/scripts/multimedia/btplayerdemo/init.sh",
            "source": "",
            "icon": "bluetooth.svg",
            "screenshot": "bluetooth.svg",
            "compatible": "imx8mm, imx8mp, imx93",
            "description": "This is an application for controlling an audio player using the Bluetooth communication protocol by the use of voice commands.\nWakeWord supported :\n    'HEY NXP'\nVoice commands supported :\n    PLAY MUSIC\n    PAUSE\n    PREVIOUS SONG\n    NEXT SONG\n    VOLUME UP\n    VOLUME DOWN\n    MUTE\n    STOP\n    STOP PLAYER\n\nThis application requires 8-MIC Array Board (8MIC-RPI-MX8) installed on the i.MX hardware (Visit NXP.com for help).\n\n\n\n\n\n\n\n\n"
        }]
    }]
    },
    {"TSN":[{
        "TSN Qbv":[{
            "name": "TSN 802.1Qbv",
            "id": "qbv_demo",
            "executable": "python3 /home/root/.nxp-demo-experience/scripts/TSN/qbv/start_demo.py",
            "source": "",
            "icon": "photo-video-solid.svg",
            "screenshot": "TSN-802.1Qbv.png",
            "compatible": "imx8mm, imx8mp",
            "description": "Enhancements to Traffic Scheduling: Time-Aware Shaper \nIt separates communication on the Ethernet network into configurable length, repeating time cycles, thereby contributing to the delivery of time-critical traffic.\nEach network node's egress ports have per-queue traffic windows which may be opened/closed at specified times.The talker-to-listener path across the network may be dedicated to this priority traffic alone, at real-time (T), causing the talker's traffic to be delivered reliably and deterministically across the network."
        }]
    }]
    },
    {"GPU":[{
        "OpenVG 2D":[{
            "name": "Tiger G2D",
            "id": "tiger",
            "executable": "/opt/viv_samples/tiger/tiger",
            "source": "",
            "icon": "cube-solid.svg",
            "screenshot": "g2d_tiger_screenshot.png",
            "compatible": "imx7ulp, imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp, imx8ulp",
            "description": "Vivante Tiger G2D, this demo shows a vector image being rotated and scaled using OpenVG."
        }],
        "GLES2":[{
            "name": "Vivante Launcher",
            "id": "vivante_launch",
            "executable": "/opt/viv_samples/es20/vv_launcher/vv_launcher",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "vivante_vv_laucher.png",
            "compatible": "imx7ulp, imx8qxpc0mek, imx8qmmek, imx8mp, imx8ulp",
            "description": "Vivante launcher demo."
        },
        {
            "name": "Cover Flow",
            "id": "cover",
            "executable": "/home/root/.nxp-demo-experience/scripts/opengl/vivante_cover_flow.sh",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "vivante_cover_flow.png",
            "compatible": "imx7ulp, imx8ulp",
            "description": "Vivante Cover Flow demo."
        },
        {
            "name": "Vivante Tutorial",
            "id": "vivante_tut",
            "executable": "/home/root/.nxp-demo-experience/scripts/opengl/vivante_tutorial7.sh",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "vivante_tutorial7.png",
            "compatible": "imx7ulp, imx8ulp",
            "description": "Vivante OpenGL tutorial"
        },
        {
            "name": "Bloom",
            "id": "bloom",
            "executable": "/opt/imx-gpu-sdk/GLES2/Bloom/GLES2.Bloom_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "bloom.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "An example of how to create a bloom effect. The idea is not to create the most accurate bloom, but something that is fairly fast to render. Instead of increasing the kernal size to get a good blur we do a fairly fast approximation by downscaling the original image to multiple smaller render-targets and then blurring these using a relative small kernel and then finally rescaling the result to the original size."
        },
        {
            "name": "Bloom",
            "id": "bloom_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/Bloom/GLES2.Bloom_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "bloom.jpg",
            "compatible": "imx7ulp",
            "description": "An example of how to create a bloom effect. The idea is not to create the most accurate bloom, but something that is fairly fast to render. Instead of increasing the kernal size to get a good blur we do a fairly fast approximation by downscaling the original image to multiple smaller render-targets and then blurring these using a relative small kernel and then finally rescaling the result to the original size."
        },
        {
            "name": "Blur",
            "id": "blur",
            "executable": "/opt/imx-gpu-sdk/GLES2/Blur/GLES2.Blur_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "blur.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "Uses the two pass linear technique and further reduces the bandwidth requirement by downscaling the 'source image' to 1/4 its size (1/2w x 1/2h) before applying the blur and and then upscaling the blurred image to provide the final image. This works well for large kernel sizes and relatively high sigma's but the downscaling produces visible artifacts with low sigma's."
        },
        {
            "name": "Blur",
            "id": "blur_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/Blur/GLES2.Blur_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "blur.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "Uses the two pass linear technique and further reduces the bandwidth requirement by downscaling the 'source image' to 1/4 its size (1/2w x 1/2h) before applying the blur and and then upscaling the blurred image to provide the final image. This works well for large kernel sizes and relatively high sigma's but the downscaling produces visible artifacts with low sigma's."
        },
        {
            "name": "EightLayerBlend",
            "id": "eight_layer",
            "executable": "/opt/imx-gpu-sdk/GLES2/EightLayerBlend/GLES2.EightLayerBlend_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "eightlayerblend.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "Creates a simple parallax scrolling effect by blending eight 32 bit per pixel 1080p layers on top of each other. This is not the most optimal way to do it as it uses eight passes. But it does provide a good example of the worst case bandwidth use for the operation. The demo was created to compare GLES to the G2D eight blend blit functionality."
        },
        {
            "name": "EightLayerBlend",
            "id": "eight_layer_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/EightLayerBlend/GLES2.EightLayerBlend_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "eightlayerblend.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "Creates a simple parallax scrolling effect by blending eight 32 bit per pixel 1080p layers on top of each other. This is not the most optimal way to do it as it uses eight passes. But it does provide a good example of the worst case bandwidth use for the operation. The demo was created to compare GLES to the G2D eight blend blit functionality."
        },
        {
            "name": "FractalShader",
            "id": "fract_shader",
            "executable": "/opt/imx-gpu-sdk/GLES2/FractalShader/GLES2.FractalShader_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "fractalshader.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "Can render both the julia and mandelbrot set using a fragment shader. This demo was used to demonstrates GPU shader performance by using up roughly 515 instructions to render each fragment while generating the julia set. It uses no textures, has no overdraw and has a minimal bandwidth requirement."
        },
        {
            "name": "FractalShader",
            "id": "fract_shader_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/FractalShader/GLES2.FractalShader_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "fractalshader.jpg",
            "compatible": "imx7ulp",
            "description": "Can render both the julia and mandelbrot set using a fragment shader. This demo was used to demonstrates GPU shader performance by using up roughly 515 instructions to render each fragment while generating the julia set. It uses no textures, has no overdraw and has a minimal bandwidth requirement."
        },
        {
            "name": "FractalShader",
            "id": "fract_shader_small2",
            "executable": "/opt/imx-gpu-sdk/GLES2/FractalShader/GLES2.FractalShader_Wayland_XDG --Window [0,0,650,400]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "fractalshader.jpg",
            "compatible": "imx8ulp",
            "description": "Can render both the julia and mandelbrot set using a fragment shader. This demo was used to demonstrates GPU shader performance by using up roughly 515 instructions to render each fragment while generating the julia set. It uses no textures, has no overdraw and has a minimal bandwidth requirement."
        },
        {
            "name": "LineBuilder101",
            "id": "line_build",
            "executable": "/opt/imx-gpu-sdk/GLES2/LineBuilder101/GLES2.LineBuilder101_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "linebuilder101.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "A simple example of dynamic line rendering using the LineBuilder helper class. The line builder has 'Add' methods for most FslBase.Math classes like BoundingBox, BoundingSphere, BoundingFrustrum, Ray, etc."
        },
        {
            "name": "LineBuilder101",
            "id": "line_build_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/LineBuilder101/GLES2.LineBuilder101_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "linebuilder101.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "A simple example of dynamic line rendering using the LineBuilder helper class. The line builder has 'Add' methods for most FslBase.Math classes like BoundingBox, BoundingSphere, BoundingFrustrum, Ray, etc."
        },
        {
            "name": "Model Loader",
            "id": "model_loader",
            "executable": "/opt/imx-gpu-sdk/GLES2/ModelLoaderBasics/GLES2.ModelLoaderBasics_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "modelloaderbasics.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "Demonstrates how to use the FslSceneImporter and Assimp to load a scene and render it using OpenGLES2. The model is rendered using a simple per pixel directional light shader."
        },
        {
            "name": "Model Loader",
            "id": "model_loader_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/ModelLoaderBasics/GLES2.ModelLoaderBasics_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "object-group-regular.svg",
            "screenshot": "modelloaderbasics.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "Demonstrates how to use the FslSceneImporter and Assimp to load a scene and render it using OpenGLES2. The model is rendered using a simple per pixel directional light shader."
        },
        {
            "name": "S03_Transform",
            "id": "transform",
            "executable": "/opt/imx-gpu-sdk/GLES2/S03_Transform/GLES2.S03_Transform_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s03_transform.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "Renders a animated vertex colored triangle. This shows how to modify the model matrix to rotate a triangle and how to utilize demoTime.DeltaTime to do frame rate independent animation."
        },
        {
            "name": "S03_Transform",
            "id": "transform_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/S03_Transform/GLES2.S03_Transform_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s03_transform.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "Renders a animated vertex colored triangle. This shows how to modify the model matrix to rotate a triangle and how to utilize demoTime.DeltaTime to do frame rate independent animation."
        },
        {
            "name": "S04_Projection",
            "id": "projection",
            "executable": "/opt/imx-gpu-sdk/GLES2/S04_Projection/GLES2.S04_Projection_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s04_projection.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "This example shows how to: - Build a perspective projection matrix - Render two simple 3d models using frame rate independent animation."
        },
        {
            "name": "S04_Projection",
            "id": "projection_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/S04_Projection/GLES2.S04_Projection_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s04_projection.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "This example shows how to: - Build a perspective projection matrix - Render two simple 3d models using frame rate independent animation."
        },
        {
            "name": "S06_Texturing",
            "id": "texturing",
            "executable": "/opt/imx-gpu-sdk/GLES2/S06_Texturing/GLES2.S06_Texturing_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s06_texturing.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "This example shows how to use the Texture class to use a texture in a cube. It also shows you how to use the ContentManager service to load a 'png' file from the Content directory into a bitmap utility class which is then used to used to create a OpenGL ES texture."
        },
        {
            "name": "S06_Texturing",
            "id": "texturing_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/S06_Texturing/GLES2.S06_Texturing_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s06_texturing.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "This example shows how to use the Texture class to use a texture in a cube. It also shows you how to use the ContentManager service to load a 'png' file from the Content directory into a bitmap utility class which is then used to used to create a OpenGL ES texture."
        },
        {
            "name": "Mapping",
            "id": "map",
            "executable": "/opt/imx-gpu-sdk/GLES2/S07_EnvMapping/GLES2.S07_EnvMapping_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s07_environmentmapping.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "This sample shows how to use a cubemap texture to simulate a reflective material. It also shows you how to use the ContentManager service to load a 'dds' file from the Content directory into a Texture utility class which is then used to used to create a OpenGL ES cubemap texture."
        },
        {
            "name": "Mapping",
            "id": "map_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/S07_EnvMapping/GLES2.S07_EnvMapping_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s07_environmentmapping.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "This sample shows how to use a cubemap texture to simulate a reflective material. It also shows you how to use the ContentManager service to load a 'dds' file from the Content directory into a Texture utility class which is then used to used to create a OpenGL ES cubemap texture."
        },
        {
            "name": "Mapping Refraction",
            "id": "refract",
            "executable": "/opt/imx-gpu-sdk/GLES2/S08_EnvMappingRefraction/GLES2.S08_EnvMappingRefraction_Wayland_XDG --Window [0,0,1280,720]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s08_environmentmappingrefraction.jpg",
            "compatible": "imx8mq, imx8mm, imx8mn, imx8qxpc0mek, imx8qmmek, imx8mp",
            "description": "This sample is a variation from the previous sample, again, a cubemap texture is used, but this time instead of simulating a reflective material a refractive material is simulated. It also shows you how to use the ContentManager service to load a 'dds' file from the Content directory into a Texture utility class which is then used to used to create a OpenGL ES cubemap texture."
        },
        {
            "name": "Mapping Refraction",
            "id": "refract_small",
            "executable": "/opt/imx-gpu-sdk/GLES2/S08_EnvMappingRefraction/GLES2.S08_EnvMappingRefraction_Wayland_XDG --Window [0,0,480,360]",
            "source": "",
            "icon": "cubes-solid.svg",
            "screenshot": "s08_environmentmappingrefraction.jpg",
            "compatible": "imx7ulp, imx8ulp",
            "description": "This sample is a variation from the previous sample, again, a cubemap texture is used, but this time instead of simulating a reflective material a refractive material is simulated. It also shows you how to use the ContentManager service to load a 'dds' file from the Content directory into a Texture utility class which is then used to used to create a OpenGL ES cubemap texture."
        }]
    }]
    }
]}
